{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2752,
     "status": "ok",
     "timestamp": 1617293067473,
     "user": {
      "displayName": "Widya Sandri",
      "photoUrl": "",
      "userId": "17469910648088057422"
     },
     "user_tz": -420
    },
    "id": "s34FtqAjfqOp",
    "outputId": "65043375-649c-4c0b-891b-a5ce5f151e0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dedek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-j3zCL8ugbYW"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import os\n",
    "import copy\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import contextlib\n",
    "import spacy\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords \n",
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "executionInfo": {
     "elapsed": 1851,
     "status": "ok",
     "timestamp": 1617293081850,
     "user": {
      "displayName": "Widya Sandri",
      "photoUrl": "",
      "userId": "17469910648088057422"
     },
     "user_tz": -420
    },
    "id": "mHPCvwGlgUMY",
    "outputId": "e472e3e4-e7ad-4ae6-af7b-7af1cd30081e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\research\\lib\\site-packages\\ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-09 23:59:59</td>\n",
       "      <td>RT @faizaufi: luar negri: bobol data pribadi p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 23:59:59</td>\n",
       "      <td>RT @bukansaurusss: \"4 orang terkaya di indones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-09 23:59:59</td>\n",
       "      <td>RT @tribunnews: Harta Kekayaan Bupati Nganjuk ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-09 23:59:58</td>\n",
       "      <td>RT @satriohendri: Sebetulnya target TKA asal C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-09 23:59:57</td>\n",
       "      <td>@FahryBakrie @msaid_didu @detikcom Demen bener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>2021-05-16 13:52:30</td>\n",
       "      <td>RT @DiajengLrst: Tingkat stress orang indonesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>2021-05-16 13:52:29</td>\n",
       "      <td>RT @billie9eulis: @MonicaChrista Soalnya di In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>2021-05-16 13:52:29</td>\n",
       "      <td>RT @ronavioleta: Jokowi Ajak Erdogan dan Sejum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>2021-05-16 13:52:27</td>\n",
       "      <td>RT @Adriandhy: Waktu Indonesia bagian hah libu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>2021-05-16 13:52:27</td>\n",
       "      <td>RT @tvstvmy: Kenyataan Media (16 Mei 2021) \\n\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet\n",
       "0      2021-05-09 23:59:59  RT @faizaufi: luar negri: bobol data pribadi p...\n",
       "1      2021-05-09 23:59:59  RT @bukansaurusss: \"4 orang terkaya di indones...\n",
       "2      2021-05-09 23:59:59  RT @tribunnews: Harta Kekayaan Bupati Nganjuk ...\n",
       "3      2021-05-09 23:59:58  RT @satriohendri: Sebetulnya target TKA asal C...\n",
       "4      2021-05-09 23:59:57  @FahryBakrie @msaid_didu @detikcom Demen bener...\n",
       "...                    ...                                                ...\n",
       "39995  2021-05-16 13:52:30  RT @DiajengLrst: Tingkat stress orang indonesi...\n",
       "39996  2021-05-16 13:52:29  RT @billie9eulis: @MonicaChrista Soalnya di In...\n",
       "39997  2021-05-16 13:52:29  RT @ronavioleta: Jokowi Ajak Erdogan dan Sejum...\n",
       "39998  2021-05-16 13:52:27  RT @Adriandhy: Waktu Indonesia bagian hah libu...\n",
       "39999  2021-05-16 13:52:27  RT @tvstvmy: Kenyataan Media (16 Mei 2021) \\n\\...\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slang = pd.read_csv(\"../Data/slang-corpus.txt\", sep='\\s*,\\s*') \n",
    "slang.head(20)\n",
    "\n",
    "tweets= pd.read_csv(\"../Data/twpy2.csv\") \n",
    "\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Bx9tijgefgFm"
   },
   "outputs": [],
   "source": [
    "class Preprocessing(object):\n",
    "   \n",
    "    def __init__(self):\n",
    "        self.stopwords = stopwords.words('indonesian')\n",
    "        self.ignored_word = ['rt','sih', 'loh', 'psx', 'ini', 'itu','eh', 'nya','si']\n",
    "        self.append_stopwords(self.ignored_word)\n",
    "            \n",
    "    def lowercase(self, text):\n",
    "        \"\"\" Lowercase text \"\"\"\n",
    "        return text.lower()\n",
    "    \n",
    "    def append_stopwords(self, text):\n",
    "        \"\"\" Append Custom Stopword \"\"\"\n",
    "        for word in text:\n",
    "            self.stopwords.append(word)\n",
    " \n",
    "    def remove_newlines(self, text):\n",
    "        \"\"\" Remove newlines characters from text \"\"\"\n",
    "        return text.replace(\"\\n\", \"\")\n",
    "    \n",
    "   \n",
    "    def remove_tabs(self,text):\n",
    "        \"\"\" Remove tab characters from text \"\"\"\n",
    "        return text.replace(\"\\t\", \"\")\n",
    "    \n",
    "   \n",
    "    def remove_digits(self,text):\n",
    "        \"\"\" Remove digits from text \"\"\"\n",
    "        return ''.join([word for word in text if not word.isdigit()])\n",
    "    \n",
    "    def remove_url(self,text):\n",
    "        \"\"\" Remove urls from text \"\"\"\n",
    "        tokens = tweet_tokenizer.tokenize(text)\n",
    "        output_array = []\n",
    "        for word in tokens:\n",
    "            cleaned_word = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', word, flags=re.MULTILINE)\n",
    "            output_array.append(cleaned_word)\n",
    "        return \" \".join(output_array)\n",
    "        \n",
    "        \n",
    "    def replace_special_chars(self,text):\n",
    "        \"\"\" Remove special characters from text \"\"\"\n",
    "        return re.sub(r'\\W+', ' ', text)\n",
    "\n",
    "    \n",
    "    def remove_multiple_whitespaces(self,text):\n",
    "        \"\"\" Remove whitespaces from text \"\"\"\n",
    "        return re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "   \n",
    "    def remove_trailing_whitespaces(self,text):\n",
    "        \"\"\" Remove whitespaces from beggining and ending text \"\"\"\n",
    "        return text.strip()\n",
    "     \n",
    "    def lemmatize(self, text):\n",
    "        \"\"\" Lemmatize words in text \"\"\"          \n",
    "        factory = StemmerFactory()\n",
    "        stemmer = factory.create_stemmer()\n",
    "        text = stemmer.stem(text)\n",
    "        return text\n",
    "\n",
    "    def remove_stopwords(self, text):\n",
    "        \"\"\" Remove stopwords from text \n",
    "        \n",
    "        :param text: text\n",
    "        :return: filtered stopwords from text\n",
    "        \"\"\"\n",
    "        tokens = tweet_tokenizer.tokenize(text)\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in self.stopwords]\n",
    "        text = \" \".join(filtered_tokens)\n",
    "        return text\n",
    "    \n",
    "    def fix_slang(self, text, slang):\n",
    "        \"\"\" Fix slang words from text \n",
    "        \n",
    "        :param text: text\n",
    "        :return: filtered slang from text\n",
    "        \"\"\"\n",
    "        tokens = tweet_tokenizer.tokenize(text)\n",
    "\n",
    "        filtered_tokens = []\n",
    "        gotcha = 0\n",
    "\n",
    "        for token in tokens:\n",
    "            for index, row in slang.iterrows():\n",
    "                if token == row[\"slang\"]:\n",
    "                    filtered_tokens.append(row[\"formal\"])\n",
    "                    gotcha = 1\n",
    "        \n",
    "            if gotcha == 0:\n",
    "                filtered_tokens.append(token)\n",
    "            else:\n",
    "                gotcha = 0\n",
    "            \n",
    "        text = \" \".join(filtered_tokens)\n",
    "\n",
    "        return text\n",
    "       \n",
    "    def clean_text(self, text, slang):\n",
    "        \"\"\" Generate a clean textual content\"\"\"\n",
    "        text = self.remove_url(text)\n",
    "        text = self.lowercase(text)\n",
    "        text = self.remove_newlines(text)\n",
    "        text = self.remove_tabs(text)\n",
    "        text = self.remove_digits(text)\n",
    "        text = self.replace_special_chars(text)\n",
    "        text = self.remove_multiple_whitespaces(text)\n",
    "        text = self.remove_trailing_whitespaces(text)        \n",
    "        text = self.fix_slang(text, slang)\n",
    "        text = self.lemmatize(text)\n",
    "        text = self.remove_stopwords(text)        \n",
    "        return text\n",
    "    \n",
    "    def clean_text_ws(self, text, slang):\n",
    "        \"\"\" Generate a clean textual content\"\"\"\n",
    "        text = self.remove_url(text)\n",
    "        text = self.lowercase(text)\n",
    "        text = self.remove_newlines(text)\n",
    "        text = self.remove_tabs(text)\n",
    "        text = self.remove_digits(text)\n",
    "        text = self.replace_special_chars(text)\n",
    "        text = self.remove_multiple_whitespaces(text)\n",
    "        text = self.remove_trailing_whitespaces(text)        \n",
    "        text = self.fix_slang(text, slang)     \n",
    "        text = self.lemmatize(text)\n",
    "        return text\n",
    "    \n",
    "    def process_text(self, data, slang):\n",
    "        result_sentence=[]\n",
    "        result_sentence_ws=[]\n",
    "        result_tokens=[] \n",
    "        for sentence in data:\n",
    "            clean_sentence = self.clean_text(sentence, slang)\n",
    "            result_sentence.append(clean_sentence)\n",
    "        return  result_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AuOztJQFf79k"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>clean_sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-09 23:59:59</td>\n",
       "      <td>RT @faizaufi: luar negri: bobol data pribadi p...</td>\n",
       "      <td>faizaufi negri bobol data pribadi duduk hack w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-09 23:59:59</td>\n",
       "      <td>RT @bukansaurusss: \"4 orang terkaya di indones...</td>\n",
       "      <td>bukansaurusss orang kaya indonesia kaya tara j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-09 23:59:59</td>\n",
       "      <td>RT @tribunnews: Harta Kekayaan Bupati Nganjuk ...</td>\n",
       "      <td>tribunnews harta kaya bupati nganjuk jaring ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-09 23:59:58</td>\n",
       "      <td>RT @satriohendri: Sebetulnya target TKA asal C...</td>\n",
       "      <td>satriohendri target tka china masuk masuk indo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-09 23:59:57</td>\n",
       "      <td>@FahryBakrie @msaid_didu @detikcom Demen bener...</td>\n",
       "      <td>fahrybakrie msaid didu detikcom suka partai ko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>2021-05-16 13:52:30</td>\n",
       "      <td>RT @DiajengLrst: Tingkat stress orang indonesi...</td>\n",
       "      <td>diajenglrst tingkat stress orang indonesia pan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>2021-05-16 13:52:29</td>\n",
       "      <td>RT @billie9eulis: @MonicaChrista Soalnya di In...</td>\n",
       "      <td>billieeulis monicachrista indonesia waris buda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>2021-05-16 13:52:29</td>\n",
       "      <td>RT @ronavioleta: Jokowi Ajak Erdogan dan Sejum...</td>\n",
       "      <td>ronavioleta jokowi ajak erdogan pimpin negara ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>2021-05-16 13:52:27</td>\n",
       "      <td>RT @Adriandhy: Waktu Indonesia bagian hah libu...</td>\n",
       "      <td>adriandhy indonesia hah libur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>2021-05-16 13:52:27</td>\n",
       "      <td>RT @tvstvmy: Kenyataan Media (16 Mei 2021) \\n\\...</td>\n",
       "      <td>tvstvmy nyata media mei sarawak mencatakan kes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                                              tweet  \\\n",
       "0      2021-05-09 23:59:59  RT @faizaufi: luar negri: bobol data pribadi p...   \n",
       "1      2021-05-09 23:59:59  RT @bukansaurusss: \"4 orang terkaya di indones...   \n",
       "2      2021-05-09 23:59:59  RT @tribunnews: Harta Kekayaan Bupati Nganjuk ...   \n",
       "3      2021-05-09 23:59:58  RT @satriohendri: Sebetulnya target TKA asal C...   \n",
       "4      2021-05-09 23:59:57  @FahryBakrie @msaid_didu @detikcom Demen bener...   \n",
       "...                    ...                                                ...   \n",
       "39995  2021-05-16 13:52:30  RT @DiajengLrst: Tingkat stress orang indonesi...   \n",
       "39996  2021-05-16 13:52:29  RT @billie9eulis: @MonicaChrista Soalnya di In...   \n",
       "39997  2021-05-16 13:52:29  RT @ronavioleta: Jokowi Ajak Erdogan dan Sejum...   \n",
       "39998  2021-05-16 13:52:27  RT @Adriandhy: Waktu Indonesia bagian hah libu...   \n",
       "39999  2021-05-16 13:52:27  RT @tvstvmy: Kenyataan Media (16 Mei 2021) \\n\\...   \n",
       "\n",
       "                                         clean_sentences  \n",
       "0      faizaufi negri bobol data pribadi duduk hack w...  \n",
       "1      bukansaurusss orang kaya indonesia kaya tara j...  \n",
       "2      tribunnews harta kaya bupati nganjuk jaring ot...  \n",
       "3      satriohendri target tka china masuk masuk indo...  \n",
       "4      fahrybakrie msaid didu detikcom suka partai ko...  \n",
       "...                                                  ...  \n",
       "39995  diajenglrst tingkat stress orang indonesia pan...  \n",
       "39996  billieeulis monicachrista indonesia waris buda...  \n",
       "39997  ronavioleta jokowi ajak erdogan pimpin negara ...  \n",
       "39998                      adriandhy indonesia hah libur  \n",
       "39999  tvstvmy nyata media mei sarawak mencatakan kes...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = tweets\n",
    "prep = Preprocessing()\n",
    "data_clean = prep.process_text(processed_data[\"tweet\"], slang)\n",
    "\n",
    "processed_data['clean_sentences'] = data_clean\n",
    "\n",
    "processed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 832,
     "status": "error",
     "timestamp": 1617285988249,
     "user": {
      "displayName": "Widya Sandri",
      "photoUrl": "",
      "userId": "17469910648088057422"
     },
     "user_tz": -420
    },
    "id": "UW3kYVIyno5_",
    "outputId": "7e3aa54f-7344-4ebc-93a8-8021ec92dfe3"
   },
   "outputs": [],
   "source": [
    "processed_data.to_csv('../Data/twpy_pre2.csv',  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AcwuPiuBFbrO"
   },
   "outputs": [],
   "source": [
    "processed_data.to_csv('drive/My Drive/Thesis/Data/small_pre_tweets_4.csv', mode = 'a', header = False,  index = False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/T2Escua4H/eE0wShIa52",
   "name": "preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
